<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>线性回归 on oyiadin</title>
    <link>https://blog.b1n.top/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
    <description>Recent content in 线性回归 on oyiadin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 07 Aug 2018 15:46:58 +0000</lastBuildDate>
    
	<atom:link href="https://blog.b1n.top/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>用Tensorflow实现逻辑与</title>
      <link>https://blog.b1n.top/posts/deep-learning/perceptron-learn-and/</link>
      <pubDate>Tue, 07 Aug 2018 15:46:58 +0000</pubDate>
      
      <guid>https://blog.b1n.top/posts/deep-learning/perceptron-learn-and/</guid>
      <description>直接使用底层 API 首先还是一样，导入需要的库。因为要画 3D 的图，需要额外导入 Axes3D。
import numpy as np import tensorflow as tf import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D  设置超参数及训练所需数据
LEARNING_RATE = 0.08 EPOCHES = 500 X_input = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]) Y_input = np.array([[0.], [0.], [0.], [1.]])  如果不带激活函数的话，训练结果会收敛于 [-0.25, 0.25, 0.25, 0.75]，虽然可以算是训练成功了，不过我不满意。将激活函数函数设为 tf.nn.relu 之后，训练结果就很不错了，很快就收敛到 [0, 0, 0, 1]。
X = tf.placeholder(tf.float32, (None, 2)) Y = tf.placeholder(tf.float32, (None, 1)) W = tf.</description>
    </item>
    
    <item>
      <title>用Tensorflow实现简单的单变量线性回归</title>
      <link>https://blog.b1n.top/posts/deep-learning/univariate-linear-regression/</link>
      <pubDate>Mon, 06 Aug 2018 20:55:07 +0000</pubDate>
      
      <guid>https://blog.b1n.top/posts/deep-learning/univariate-linear-regression/</guid>
      <description>这里用的是 tf 底层 API，先导入所需要的包，并设置好一些超参数
import numpy as np import matplotlib.pyplot as plt import tensorflow as tf LEARNING_RATE = 0.001 EPOCHES = 200 BATCH_SIZE = 10  然后自己生成随机数据点，用以稍后的训练，顺便把数据点先画好
HOW_MANY = 80 # 数据点个数 true_w = int(np.random.randn() * 7) true_b = int(np.random.randn() * 4) # 真正的 w 与 b，为了方便比对，均取整 train_X = np.random.rand(HOW_MANY) * 15 noise = np.random.randn(HOW_MANY) * 3.5 # 随机噪音，有正有负 train_Y = true_w * train_X + true_b + noise plt.plot(train_X, train_Y, &#39;o&#39;) plt.</description>
    </item>
    
  </channel>
</rss>