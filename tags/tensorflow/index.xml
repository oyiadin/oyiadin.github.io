<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensorflow on oyiadin</title>
    <link>https://blog.b1n.top/tags/tensorflow/</link>
    <description>Recent content in Tensorflow on oyiadin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 07 Aug 2018 15:46:58 +0000</lastBuildDate>
    
	<atom:link href="https://blog.b1n.top/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>用Tensorflow实现逻辑与</title>
      <link>https://blog.b1n.top/posts/deep-learning/perceptron-learn-and/</link>
      <pubDate>Tue, 07 Aug 2018 15:46:58 +0000</pubDate>
      
      <guid>https://blog.b1n.top/posts/deep-learning/perceptron-learn-and/</guid>
      <description>直接使用底层 API 首先还是一样，导入需要的库。因为要画 3D 的图，需要额外导入 Axes3D。
import numpy as np import tensorflow as tf import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D  设置超参数及训练所需数据
LEARNING_RATE = 0.08 EPOCHES = 500 X_input = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]) Y_input = np.array([[0.], [0.], [0.], [1.]])  如果不带激活函数的话，训练结果会收敛于 [-0.25, 0.25, 0.25, 0.75]，虽然可以算是训练成功了，不过我不满意。将激活函数函数设为 tf.nn.relu 之后，训练结果就很不错了，很快就收敛到 [0, 0, 0, 1]。
X = tf.placeholder(tf.float32, (None, 2)) Y = tf.placeholder(tf.float32, (None, 1)) W = tf.</description>
    </item>
    
    <item>
      <title>用Tensorflow实现简单的单变量线性回归</title>
      <link>https://blog.b1n.top/posts/deep-learning/univariate-linear-regression/</link>
      <pubDate>Mon, 06 Aug 2018 20:55:07 +0000</pubDate>
      
      <guid>https://blog.b1n.top/posts/deep-learning/univariate-linear-regression/</guid>
      <description>这里用的是 tf 底层 API，先导入所需要的包，并设置好一些超参数
import numpy as np import matplotlib.pyplot as plt import tensorflow as tf LEARNING_RATE = 0.001 EPOCHES = 200 BATCH_SIZE = 10  然后自己生成随机数据点，用以稍后的训练，顺便把数据点先画好
HOW_MANY = 80 # 数据点个数 true_w = int(np.random.randn() * 7) true_b = int(np.random.randn() * 4) # 真正的 w 与 b，为了方便比对，均取整 train_X = np.random.rand(HOW_MANY) * 15 noise = np.random.randn(HOW_MANY) * 3.5 # 随机噪音，有正有负 train_Y = true_w * train_X + true_b + noise plt.plot(train_X, train_Y, &#39;o&#39;) plt.</description>
    </item>
    
    <item>
      <title>深度学习开发环境配置记录 (tf&#43;torch)</title>
      <link>https://blog.b1n.top/posts/deep-learning/a-note-on-configure-my-deep-learning-developing-environment/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.b1n.top/posts/deep-learning/a-note-on-configure-my-deep-learning-developing-environment/</guid>
      <description>Versions  CPU: Intel i5-6300HQ (2.30GHz) GPU: NVIDIA GeForce GTX 950M
 Windows 10 Education
 Ubuntu 16.04 LTS (VirtualBox 5.2.16)
 Python
 Python 3.6.5 (Windows, Anaconda) Python 3.5.2 (Ubuntu)  Libraries
 numpy 1.15.0 pandas 0.23.3 tensorflow 1.9.0 torch 0.4.0 requests 2.9.1 beautifulsoup4 4.4.1  CUDA Toolkit 9.0
 cuDNN 7.0.5 (Dec 5, 2017), for CUDA 9.0
  Details 我的 ubuntu 一直都是配好的，不再赘述。为了便利，我选择使用 Anaconda，安装很容易，只需一路 Next 就行。numpy、pandas、requests 与 bs4 的安装也都很简单，sudo pip3 install 就能直接装上。由于 VBox 不能很好地利用我的显卡，我仅在 Windows 上安装了 GPU 版 Tensorflow，Ubuntu 上只安装了 CPU 版。</description>
    </item>
    
  </channel>
</rss>