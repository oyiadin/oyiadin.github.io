

<!DOCTYPE html>
<html lang="en" xmlns:v-bind="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8">
    <meta name="X-UA-Compatible" content="IE=edge">
    <meta name="author" content="oyiadin">

    <title>用Tensorflow实现简单的单变量线性回归 - Chen&#39;s Notebook</title>
    <meta name="description" content="">

    <meta name="keywords"
          content="">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <meta content="yes" name="apple-mobile-web-app-capable">
    <meta content="black" name="apple-mobile-web-app-status-bar-style">
    <meta content="telephone=no" name="format-detection">
    <meta name="renderer" content="webkit">
    <noscript>
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400|Montserrat|Anonymous+Pro:400|Material+Icons"/>
    </noscript>
    <link rel="short icon" href="../../../favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="../../../css/bootstrap.min.css">
    <link rel="stylesheet" href="../../../css/mprogress.css">
    <link rel="stylesheet" href="../../../css/open-iconic.min.css">
    <link rel="stylesheet" href="../../../css/style.css">
    <link rel="stylesheet" href="../../../css/prism.css">
    <link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="../../../atom.xml">
    <script>
        /*!
         loadCSS: load a CSS file asynchronously.
         [c]2014 @scottjehl, Filament Group, Inc.
         Licensed MIT
         */
        function loadCSS( href, before, media ){
            "use strict";
            var ss = window.document.createElement( "link" );
            var ref = before || window.document.getElementsByTagName( "script" )[ 0 ];
            var sheets = window.document.styleSheets;
            ss.rel = "stylesheet";
            ss.href = href;
            ss.media = "only x";
            ref.parentNode.insertBefore( ss, ref );
            function toggleMedia(){
                var defined;
                for( var i = 0; i < sheets.length; i++ ){
                    if( sheets[ i ].href && sheets[ i ].href.indexOf( href ) > -1 ){
                        defined = true;
                    }
                }
                if( defined ){
                    ss.media = media || "all";
                }
                else {
                    setTimeout( toggleMedia );
                }
            }
            toggleMedia();
            return ss;
        }
    </script>
</head>
<body>

<div id="app">
    <nav ref="navBar" class="navbar fixed-top navbar-light">
    <div id="global-loading-indicator" class="progress-line global-loading-indicator"></div>
    <div id="nav_background" class="nav-background"></div>
    <div style="padding-left: 15px;padding-right: 15px" class="container container-narrow nav-content">

        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" data-toggle="adropdown">
            <span class="oi" data-glyph="menu"></span>
        </button>
        <a id="nav_title" class="navbar-brand Montserrat" href="/">
            Chen&#39;s Notebook
        </a>
        <div class="float-right navbar-dark nav-icon-group">
            <div class="dropdown">
                <ul class="dropdown-menu" id="collapsed_nav">
                    <li><a href="/" class="a-block nav-icon">Archive</a></li>
                    
                    
                    <li><a href="/about/index.html" class="a-block nav-icon">About Me &amp; Links</a></li>
                    
                    
                    <li><a href="/atom.xml" target="_blank" class="a-block">
                            <span data-glyph="rss" class="oi nav-icon"></span>
                        </a>
                    </li>
                    
                </ul>
            </div>

        </div>
    </div>
</nav>
    <div class="container container-narrow">

        <div ref="pageHead"
             v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"
             class="page-head">
            <a href="/">
                <h2>Chen&#39;s Notebook</h2>
                <h5>to cultivate curiosity</h5>
            </a>
        </div>

<div class="row stream-container">
    <div class="card-container">

        <div class="card card-item clear-border card-top-patch card-clear-hover">
            

            <div class="card-item-container clear-flex-xs">
                <div class="card-inner-cell">
                    <h2>用Tensorflow实现简单的单变量线性回归</h2>

                    <div>
                        <p>
                            <time datetime="2018-08-06T12:55:07.000Z" itemprop="datePublished">
                                2018-08-06 20:55
                            </time>
                            

                            
                            
                            <span class="oi" data-glyph="tag" style="vertical-align: middle; margin-left: 5px"> </span>&nbsp;
                            
                            <a href='/tags/Tensorflow/'>Tensorflow</a>
                            
                            ,
                            
                            
                            <a href='/tags/深度学习/'>深度学习</a>
                            
                            ,
                            
                            
                            <a href='/tags/线性回归/'>线性回归</a>
                            
                            
                            
                        </p>
                    </div>


                    <p class=" post-block-desc">
                        <p>这里用的是 tf 底层 API，先导入所需要的包，并设置好一些超参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">0.001</span></span><br><span class="line">EPOCHES = <span class="number">200</span></span><br><span class="line">BATCH_SIZE = <span class="number">10</span></span><br></pre></td></tr></table></figure>
<p>然后自己生成随机数据点，用以稍后的训练，顺便把数据点先画好</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">HOW_MANY = <span class="number">80</span>  <span class="comment"># 数据点个数</span></span><br><span class="line"></span><br><span class="line">true_w = int(np.random.randn() * <span class="number">7</span>)</span><br><span class="line">true_b = int(np.random.randn() * <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 真正的 w 与 b，为了方便比对，均取整</span></span><br><span class="line"></span><br><span class="line">train_X = np.random.rand(HOW_MANY) * <span class="number">15</span></span><br><span class="line">noise = np.random.randn(HOW_MANY) * <span class="number">3.5</span>  <span class="comment"># 随机噪音，有正有负</span></span><br><span class="line">train_Y = true_w * train_X + true_b + noise</span><br><span class="line"></span><br><span class="line">plt.plot(train_X, train_Y, <span class="string">'o'</span>)</span><br><span class="line">plt.plot(train_X, train_Y - noise, <span class="string">'g'</span>, label=<span class="string">'real'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'generate successfully'</span>)</span><br></pre></td></tr></table></figure>
<p>设置所需节点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32)</span><br><span class="line">Y = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line">w = tf.Variable(tf.zeros(()))</span><br><span class="line">b = tf.Variable(tf.zeros(()))  <span class="comment"># w and b are all scalars</span></span><br></pre></td></tr></table></figure>
<p>设置模型（线性）和 loss function、optimizer</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred = w * X + b</span><br><span class="line">loss = tf.reduce_sum((Y - pred) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)</span><br></pre></td></tr></table></figure>
<p>初始化 Variables</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure>
<p>分批投喂数据进行训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 仍在 with 里边</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(EPOCHES):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(<span class="number">0</span>, HOW_MANY, BATCH_SIZE):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: train_X[batch:batch+BATCH_SIZE], Y: train_Y[batch:batch+BATCH_SIZE]&#125;)</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch #&#123;&#125;, loss = &#123;&#125;'</span>.format(i+<span class="number">1</span>, sess.run(loss, feed_dict=&#123;X: train_X, Y: train_Y&#125;)))</span><br></pre></td></tr></table></figure>
<p>训练完成，输出相关信息，完成图表并展示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 仍在 with 里边</span></span><br><span class="line">    print(<span class="string">'Trained successfully.'</span>)</span><br><span class="line">    print(<span class="string">'true_w = &#123;&#125;, true_b = &#123;&#125;'</span>.format(true_w, true_b))</span><br><span class="line">    print(<span class="string">'pred_w = &#123;&#125;, pred_b = &#123;&#125;'</span>.format(w.eval(), b.eval()))</span><br><span class="line"></span><br><span class="line">    _x = np.linspace(<span class="number">0</span>, <span class="number">15</span>)</span><br><span class="line">    _y = w.eval() * _x + b.eval()</span><br><span class="line"></span><br><span class="line">plt.plot(_x, _y.T, <span class="string">'r'</span>, label=<span class="string">'prediction'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><del>如果学习率设置得太高，可能会导致在 Optimizer 找到合适方向前，loss function 的值就已经爆表了，</del>最后得到的 w 跟 b 都是 NaN。所以比较稳妥的方法是，减小学习率，增加训练次数。</p>
<blockquote>
<p>Update: 对于随机梯度下降来说，<a href="https://www.zhihu.com/question/66200879/answer/239468705" target="_blank" rel="noopener">Tensorflow 会自动记录节点的运算规则并求导</a>，不存在“找不到合适方向”的情况。不过如果 <code>loss function</code> 越来越高的话，基本都是由于学习率过高，不断跨过沟底。同时，沟壁的梯度（一般）越远离极小值点则越大（所以更新的步伐也越来越大），最终造成 <code>loss function</code> 的值越来越离谱。</p>
</blockquote>
<p>试着跑了一下，能得到如下输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">true_w = <span class="number">-3</span>, true_b = <span class="number">0</span></span><br><span class="line">pred_w = <span class="number">-2.9783382415771484</span>, pred_b = <span class="number">0.7763855457305908</span></span><br></pre></td></tr></table></figure>
<p><img src="univariate-linear-regression.png" alt="运行效果"></p>

                    </p>

                    <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="../perceptron-learn-and/">
        Previous post: 用Tensorflow实现逻辑与
    </a>
    
    <span class="page-number"></span>
    
    <a class="older-posts" href="../a-note-on-configure-my-deep-learning-developing-environment/">
        Next post: 深度学习开发环境配置记录 (tf+torch)
    </a>
    
</nav>

                    
<a id="comments"></a>
<div id="disqus_thread"></div>
<script>var disqus_shortname = 'oyiadin';
    var disqus_identifier = '2018/deep-learning/univariate-linear-regression/';
    var disqus_title = '用Tensorflow实现简单的单变量线性回归';
    var disqus_url = 'https://blog.b1n.top/2018/deep-learning/univariate-linear-regression/';
    (function () {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();</script>
<script id="dsq-count-scr" src="//oyiadin.disqus.com/count.js" async></script>

                </div>
            </div>
        </div>
    </div>
</div>

<footer>
    <p>
        &copy;&nbsp;2019&nbsp;<a target="_blank"
                                                               href="">oyiadin</a>
    </p>

    
    <p>Theme&nbsp;<a target="_blank"
                     href="https://github.com/SumiMakito/hexo-theme-journal">Journal.</a>&nbsp;by&nbsp;<a
                target="_blank" href="https://www.keep.moe">Makito</a>
    </p>
    

    <p>
        Proudly published with&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>
    </p>
</footer>

</div>
</div>
</div>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="../../../js/popper.min.js"></script>
<script src="../../../js/bootstrap.min.js"></script>
<script src=" ../../../js/vue.min.js"></script>
<script src=" ../../../js/journal.js"></script>
<script>
    loadCSS("//fonts.googleapis.com/css?family=Source+Sans+Pro:400|Montserrat|Anonymous+Pro:400|Material+Icons");
</script>


<script>
    $(document).ready(function () {
        $("#global-loading-indicator").fadeOut(600);
    });
</script>

</body>
</html>
